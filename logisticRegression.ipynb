{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiment on top 5 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['data/elections', 'data/politics', 'data/white_house', 'data/immigration', 'data/healthcare']\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(url):\n",
    "    train_data = pd.read_csv(f'{url}/train/{url.split(\"/\")[1]}_train.csv')\n",
    "    train_data = train_data[(train_data['bias'] == 0) | (train_data['bias'] == 2)]\n",
    "    train_data['content'] = train_data['content'].apply(lambda x: x.lower())\n",
    "    \n",
    "    test_data = pd.read_csv(f'{url}/test/{url.split(\"/\")[1]}_test.csv')\n",
    "    test_data = test_data[(test_data['bias'] == 0) | (test_data['bias'] == 2)]\n",
    "    test_data['content'] = test_data['content'].apply(lambda x: x.lower())\n",
    "    \n",
    "    tfid = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    x_train = train_data['content'].values\n",
    "    x_train = tfid.fit_transform(x_train)\n",
    "    y_train = train_data['bias'].values\n",
    "    \n",
    "    x_test = test_data['content'].values\n",
    "    x_test = tfid.transform(x_test)\n",
    "    y_test = test_data['bias'].values\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label=2)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=2)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=2)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return acc, precision, recall, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment(url):\n",
    "    x_train, y_train, x_test, y_test = preprocess_data(url)\n",
    "    model = train_model(x_train, y_train)\n",
    "    return predict_on_test_data(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elections Accuracy: 0.6579\n",
      "elections Precision: 0.6696\n",
      "elections Recall: 0.4133\n",
      "elections F1: 0.5111\n",
      "\n",
      "\n",
      "politics Accuracy: 0.6619\n",
      "politics Precision: 0.6313\n",
      "politics Recall: 0.8642\n",
      "politics F1: 0.7296\n",
      "\n",
      "\n",
      "white_house Accuracy: 0.6451\n",
      "white_house Precision: 0.6430\n",
      "white_house Recall: 0.7311\n",
      "white_house F1: 0.6842\n",
      "\n",
      "\n",
      "immigration Accuracy: 0.6623\n",
      "immigration Precision: 0.6475\n",
      "immigration Recall: 0.9008\n",
      "immigration F1: 0.7534\n",
      "\n",
      "\n",
      "healthcare Accuracy: 0.6235\n",
      "healthcare Precision: 0.5912\n",
      "healthcare Recall: 0.9501\n",
      "healthcare F1: 0.7289\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6501\n",
      "Average Precision: 0.6365\n",
      "Average Recall: 0.7719\n",
      "Average F1: 0.6814\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = 0\n",
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "avg_f1 = 0\n",
    "cms = []\n",
    "\n",
    "for url in urls:\n",
    "    topic = url.split(\"/\")[1]\n",
    "    \n",
    "    accuracy, precision, recall, f1, cm = runExperiment(url)\n",
    "    \n",
    "    avg_accuracy += accuracy\n",
    "    avg_precision += precision\n",
    "    avg_recall += recall\n",
    "    avg_f1 += f1\n",
    "    cms.append(cm)\n",
    "    \n",
    "    print(f'{topic} Accuracy: {accuracy:.4f}')\n",
    "    print(f'{topic} Precision: {precision:.4f}')\n",
    "    print(f'{topic} Recall: {recall:.4f}')\n",
    "    print(f'{topic} F1: {f1:.4f}\\n\\n')\n",
    "    \n",
    "avg_accuracy /= len(urls)\n",
    "avg_recall /= len(urls)\n",
    "avg_precision /= len(urls)\n",
    "avg_f1 /= len(urls)\n",
    "\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Left</th>\n",
       "      <th>Predicted Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Left</th>\n",
       "      <td>2489</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Right</th>\n",
       "      <td>1211</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Left  Predicted Right\n",
       "Actual Left             2489             1536\n",
       "Actual Right            1211             2693"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sum(cms)\n",
    "\n",
    "data_cm = pd.DataFrame(cm, columns=['Predicted Left', 'Predicted Right'], index=['Actual Left', 'Actual Right'])\n",
    "data_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.636507</td>\n",
       "      <td>0.771884</td>\n",
       "      <td>0.681436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall        F1\n",
       "Logistic Regression  0.650135   0.636507  0.771884  0.681436"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "data = [[avg_accuracy, avg_precision, avg_recall, avg_f1]]\n",
    "data_metrics = pd.DataFrame(data, columns=cols, index=['Logistic Regression'])\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiment on top 5 categories using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_with_PCA(url):\n",
    "    train_data = pd.read_csv(f'{url}/train/{url.split(\"/\")[1]}_train.csv')\n",
    "    train_data = train_data[(train_data['bias'] == 0) | (train_data['bias'] == 2)]\n",
    "    train_data['content'] = train_data['content'].apply(lambda x: x.lower())\n",
    "    \n",
    "    test_data = pd.read_csv(f'{url}/test/{url.split(\"/\")[1]}_test.csv')\n",
    "    test_data = test_data[(test_data['bias'] == 0) | (test_data['bias'] == 2)]\n",
    "    test_data['content'] = test_data['content'].apply(lambda x: x.lower())\n",
    "    \n",
    "    tfid = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    x_train = train_data['content'].values\n",
    "    x_train = tfid.fit_transform(x_train)\n",
    "    y_train = train_data['bias'].values\n",
    "    \n",
    "    x_test = test_data['content'].values\n",
    "    x_test = tfid.transform(x_test)\n",
    "    y_test = test_data['bias'].values\n",
    "    \n",
    "    pca = PCA(n_components=0.9)\n",
    "    transformed_x_train = pca.fit_transform(x_train.toarray())\n",
    "    transformed_x_test = pca.transform(x_test.toarray())\n",
    "    \n",
    "    return transformed_x_train, y_train, transformed_x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment_with_pca(url):\n",
    "    x_train, y_train, x_test, y_test = preprocess_data_with_PCA(url)\n",
    "    model = train_model(x_train, y_train)\n",
    "    return predict_on_test_data(model, x_test, y_test), x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components of X_test: 611\n",
      "elections Accuracy: 0.6558\n",
      "elections Precision: 0.6645\n",
      "elections Recall: 0.4133\n",
      "elections F1: 0.5096\n",
      "\n",
      "\n",
      "Components of X_test: 314\n",
      "politics Accuracy: 0.6539\n",
      "politics Precision: 0.6265\n",
      "politics Recall: 0.8525\n",
      "politics F1: 0.7222\n",
      "\n",
      "\n",
      "Components of X_test: 214\n",
      "white_house Accuracy: 0.6405\n",
      "white_house Precision: 0.6415\n",
      "white_house Recall: 0.7170\n",
      "white_house F1: 0.6772\n",
      "\n",
      "\n",
      "Components of X_test: 179\n",
      "immigration Accuracy: 0.6612\n",
      "immigration Precision: 0.6474\n",
      "immigration Recall: 0.8969\n",
      "immigration F1: 0.7520\n",
      "\n",
      "\n",
      "Components of X_test: 173\n",
      "healthcare Accuracy: 0.6190\n",
      "healthcare Precision: 0.5886\n",
      "healthcare Recall: 0.9459\n",
      "healthcare F1: 0.7257\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6461\n",
      "Average Precision: 0.6337\n",
      "Average Recall: 0.7651\n",
      "Average F1: 0.6773\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = 0\n",
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "avg_f1 = 0\n",
    "cms = []\n",
    "\n",
    "for url in urls:\n",
    "    topic = url.split(\"/\")[1]\n",
    "    \n",
    "    experiment_results, x_test = runExperiment_with_pca(url)\n",
    "    print(f\"Components of X_test: {x_test.shape[1]}\")\n",
    "    accuracy, precision, recall, f1, cm = experiment_results\n",
    "    \n",
    "    #  accuracy, precision, recall, f1, cm, x_test = runExperiment(url)\n",
    "    \n",
    "    avg_accuracy += accuracy\n",
    "    avg_precision += precision\n",
    "    avg_recall += recall\n",
    "    avg_f1 += f1\n",
    "    cms.append(cm)\n",
    "    \n",
    "    print(f'{topic} Accuracy: {accuracy:.4f}')\n",
    "    print(f'{topic} Precision: {precision:.4f}')\n",
    "    print(f'{topic} Recall: {recall:.4f}')\n",
    "    print(f'{topic} F1: {f1:.4f}\\n\\n')\n",
    "    \n",
    "avg_accuracy /= len(urls)\n",
    "avg_recall /= len(urls)\n",
    "avg_precision /= len(urls)\n",
    "avg_f1 /= len(urls)\n",
    "\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Left</th>\n",
       "      <th>Predicted Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Left</th>\n",
       "      <td>2481</td>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Right</th>\n",
       "      <td>1233</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Left  Predicted Right\n",
       "Actual Left             2481             1544\n",
       "Actual Right            1233             2671"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sum(cms)\n",
    "\n",
    "data_cm = pd.DataFrame(cm, columns=['Predicted Left', 'Predicted Right'], index=['Actual Left', 'Actual Right'])\n",
    "data_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.636507</td>\n",
       "      <td>0.771884</td>\n",
       "      <td>0.681436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression with PCA</th>\n",
       "      <td>0.646089</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.765136</td>\n",
       "      <td>0.677337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy  Precision    Recall        F1\n",
       "Logistic Regression           0.650135   0.636507  0.771884  0.681436\n",
       "Logistic Regression with PCA  0.646089   0.633700  0.765136  0.677337"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "data = [[avg_accuracy, avg_precision, avg_recall, avg_f1]]\n",
    "new_data_metrics = pd.DataFrame(data, columns=cols, index=['Logistic Regression with PCA'])\n",
    "\n",
    "result = pd.concat([data_metrics, new_data_metrics])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiment on top 5 categories using SparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_with_SPCA(url):\n",
    "    topic = url.split(\"/\")[1]\n",
    "    train_data = pd.read_csv(f'{url}/train/{topic}_train.csv')\n",
    "    train_data = train_data[(train_data['bias'] == 0) | (train_data['bias'] == 2)]\n",
    "    train_data['content'] = train_data['content'].apply(lambda x: x.lower())\n",
    "    \n",
    "    test_data = pd.read_csv(f'{url}/test/{topic}_test.csv')\n",
    "    test_data = test_data[(test_data['bias'] == 0) | (test_data['bias'] == 2)]\n",
    "    test_data['content'] = test_data['content'].apply(lambda x: x.lower())\n",
    "    \n",
    "    tfid = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    x_train = train_data['content'].values\n",
    "    x_train = tfid.fit_transform(x_train)\n",
    "    y_train = train_data['bias'].values\n",
    "    \n",
    "    x_test = test_data['content'].values\n",
    "    x_test = tfid.transform(x_test)\n",
    "    y_test = test_data['bias'].values\n",
    "    \n",
    "    # spca = SparsePCA(n_components=400)\n",
    "    # transformed_x_train = spca.fit_transform(x_train.toarray())\n",
    "    # transformed_x_test = spca.transform(x_test.toarray())\n",
    "    \n",
    "    num_components = {'elections': 600,  'politics': 311, 'white_house': 211, 'immigration': 176, 'healthcare': 170}\n",
    "\n",
    "    svd = TruncatedSVD(n_components=num_components[topic])\n",
    "    transformed_x_train = svd.fit_transform(x_train)\n",
    "    transformed_x_test = svd.transform(x_test)\n",
    "    \n",
    "    # explained_variance = (svd.singular_values_ ** 2) / (np.sum(svd.singular_values_ ** 2))\n",
    "    # cumulative_variance = np.cumsum(explained_variance)\n",
    "    # n_componenet_needed = np.where(cumulative_variance >= 0.90)[0][0] + 1\n",
    "    # topic = url.split(\"/\")[1]\n",
    "    # print(f\"Number of components needed to capture 90% variance for topic {topic}: {n_componenet_needed}\")\n",
    "    \n",
    "    return transformed_x_train, y_train, transformed_x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment_with_spca(url):\n",
    "    x_train, y_train, x_test, y_test = preprocess_data_with_SPCA(url)\n",
    "    model = train_model(x_train, y_train)\n",
    "    return predict_on_test_data(model, x_test, y_test), x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components of X_test: 600\n",
      "elections Accuracy: 0.6567\n",
      "elections Precision: 0.6656\n",
      "elections Recall: 0.4153\n",
      "elections F1: 0.5115\n",
      "\n",
      "\n",
      "Components of X_test: 311\n",
      "politics Accuracy: 0.6564\n",
      "politics Precision: 0.6287\n",
      "politics Recall: 0.8525\n",
      "politics F1: 0.7237\n",
      "\n",
      "\n",
      "Components of X_test: 211\n",
      "white_house Accuracy: 0.6442\n",
      "white_house Precision: 0.6433\n",
      "white_house Recall: 0.7258\n",
      "white_house F1: 0.6821\n",
      "\n",
      "\n",
      "Components of X_test: 176\n",
      "immigration Accuracy: 0.6634\n",
      "immigration Precision: 0.6475\n",
      "immigration Recall: 0.9046\n",
      "immigration F1: 0.7548\n",
      "\n",
      "\n",
      "Components of X_test: 170\n",
      "healthcare Accuracy: 0.6190\n",
      "healthcare Precision: 0.5886\n",
      "healthcare Recall: 0.9459\n",
      "healthcare F1: 0.7257\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6479\n",
      "Average Precision: 0.6347\n",
      "Average Recall: 0.7688\n",
      "Average F1: 0.6795\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = 0\n",
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "avg_f1 = 0\n",
    "cms = []\n",
    "\n",
    "for url in urls:\n",
    "    topic = url.split(\"/\")[1]\n",
    "    \n",
    "    experiment_results, x_test = runExperiment_with_spca(url)\n",
    "    print(f\"Components of X_test: {x_test.shape[1]}\")\n",
    "    accuracy, precision, recall, f1, cm = experiment_results\n",
    "    \n",
    "    #  accuracy, precision, recall, f1, cm, x_test = runExperiment(url)\n",
    "    \n",
    "    avg_accuracy += accuracy\n",
    "    avg_precision += precision\n",
    "    avg_recall += recall\n",
    "    avg_f1 += f1\n",
    "    cms.append(cm)\n",
    "    \n",
    "    print(f'{topic} Accuracy: {accuracy:.4f}')\n",
    "    print(f'{topic} Precision: {precision:.4f}')\n",
    "    print(f'{topic} Recall: {recall:.4f}')\n",
    "    print(f'{topic} F1: {f1:.4f}\\n\\n')\n",
    "    \n",
    "avg_accuracy /= len(urls)\n",
    "avg_recall /= len(urls)\n",
    "avg_precision /= len(urls)\n",
    "avg_f1 /= len(urls)\n",
    "\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Left</th>\n",
       "      <th>Predicted Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Left</th>\n",
       "      <td>2482</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Right</th>\n",
       "      <td>1221</td>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Left  Predicted Right\n",
       "Actual Left             2482             1543\n",
       "Actual Right            1221             2683"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sum(cms)\n",
    "\n",
    "data_cm = pd.DataFrame(cm, columns=['Predicted Left', 'Predicted Right'], index=['Actual Left', 'Actual Right'])\n",
    "data_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.636507</td>\n",
       "      <td>0.771884</td>\n",
       "      <td>0.681436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression with PCA</th>\n",
       "      <td>0.646089</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.765136</td>\n",
       "      <td>0.677337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression with TruncatedSVD</th>\n",
       "      <td>0.647936</td>\n",
       "      <td>0.634742</td>\n",
       "      <td>0.768826</td>\n",
       "      <td>0.679533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Accuracy  Precision    Recall        F1\n",
       "Logistic Regression                    0.650135   0.636507  0.771884  0.681436\n",
       "Logistic Regression with PCA           0.646089   0.633700  0.765136  0.677337\n",
       "Logistic Regression with TruncatedSVD  0.647936   0.634742  0.768826  0.679533"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "data = [[avg_accuracy, avg_precision, avg_recall, avg_f1]]\n",
    "new_data_metrics = pd.DataFrame(data, columns=cols, index=['Logistic Regression with TruncatedSVD'])\n",
    "\n",
    "result = pd.concat([result, new_data_metrics])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCI_4022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
